{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzyuC5MikOgrs8MOqUtIXA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mircus/WalkGPT/blob/main/WalkGPT_v1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import sched_get_priority_min\n",
        "!pip install sparqlwrapper\n",
        "!pip install torch torchvision\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-2.0.1+cu118.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-2.0.1+cu118.html\n",
        "!pip install -q torch-cluster -f https://pytorch-geometric.com/whl/torch-2.0.1+cu118.html\n",
        "!pip install -q torch-spline-conv -f https://pytorch-geometric.com/whl/torch-2.0.1+cu118.html\n",
        "!pip install -q torch-geometric\n",
        "!pip install transformers\n",
        "\n",
        "# Necessary imports\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import random\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "\n",
        "# Query DBpedia for actor-movie pairs\n",
        "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
        "sparql.setQuery(\"\"\"\n",
        "    SELECT ?actor ?actorLabel ?movie ?movieLabel ?abstract ?genreLabel\n",
        "    WHERE {\n",
        "        ?actor rdf:type dbo:Actor .\n",
        "        ?movie rdf:type dbo:Film .\n",
        "        ?movie dbo:starring ?actor .\n",
        "        ?actor rdfs:label ?actorLabel .\n",
        "        ?movie rdfs:label ?movieLabel .\n",
        "        ?movie dbo:abstract ?abstract .\n",
        "        ?movie dbo:genre ?genre .\n",
        "        ?genre rdfs:label ?genreLabel .\n",
        "        FILTER (LANG(?actorLabel) = 'en')\n",
        "        FILTER (LANG(?movieLabel) = 'en')\n",
        "        FILTER (LANG(?abstract) = 'en')\n",
        "        FILTER (LANG(?genreLabel) = 'en')\n",
        "    }\n",
        "    LIMIT 1000\n",
        "\"\"\")\n",
        "sparql.setReturnFormat(JSON)\n",
        "results = sparql.query().convert()\n",
        "rows = results['results']['bindings']\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "# Cleaning up the dataframe\n",
        "df['actor_name'] = df['actorLabel'].apply(lambda row: row['value'])\n",
        "df['title_name'] = df['movieLabel'].apply(lambda row: row['value'])\n",
        "df['abstract'] = df['abstract'].apply(lambda row: row['value'])\n",
        "df['genre'] = df['genreLabel'].apply(lambda row: row['value'])\n",
        "df = df[['actor_name', 'title_name', 'abstract', 'genre']]\n",
        "\n",
        "# Create graph\n",
        "G = nx.Graph()\n",
        "\n",
        "# Add nodes and edges to the graph\n",
        "for index, row in df.iterrows():\n",
        "    G.add_node(row['actor_name'], type='actor')\n",
        "    G.add_node(row['title_name'], type='movie')\n",
        "    G.add_edge(row['actor_name'], row['title_name'],\n",
        "               relation=f\"{row['actor_name']} starred in {row['title_name']}, a {row['genre']}, which is about: {row['abstract']}\")\n",
        "\n",
        "# Define function for random walks\n",
        "def generate_random_walks(G, num_walks=10, walk_length=10):\n",
        "    walks = []\n",
        "    nodes = list(G.nodes())\n",
        "    for _ in range(num_walks):\n",
        "        start_node = random.choice(nodes)\n",
        "        walk = [start_node]\n",
        "        for _ in range(walk_length):\n",
        "            cur_node = walk[-1]\n",
        "            neighbors = list(nx.all_neighbors(G, cur_node))\n",
        "            neighbors = [n for n in neighbors if n not in walk[-2:]]  # prevent immediate backtracking\n",
        "            if neighbors:\n",
        "                walk.append(random.choice(neighbors))\n",
        "            else:\n",
        "                break\n",
        "        walks.append(walk)\n",
        "    return walks\n",
        "\n",
        "# Generate random walks\n",
        "random_walks = generate_random_walks(G)\n",
        "\n",
        "# Convert walks into a seed text for the language model\n",
        "seed_text = \". \".join([\" \".join([G[actor][movie]['relation'] for actor, movie in zip(walk, walk[1:])]) for walk in random_walks])\n",
        "\n",
        "#print(seed_text)\n",
        "\n",
        "seed_text1 = \"\"\"\n",
        "Given the following details, imagine a suspenseful thriller movie where the narratives from each series are intertwined, and the actors mentioned take on new roles. Create a plot full of unexpected twists and resolutions:\n",
        "\"\"\" + seed_text\n",
        "\n",
        "print(seed_text1)"
      ],
      "metadata": {
        "id": "rjOSD95D51Ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trim the seed text to a specified maximum length\n",
        "max_length_seed = 500\n",
        "if len(seed_text1) > max_length_seed:\n",
        "    # Find the last period within our desired length and trim there\n",
        "    end_position = seed_text1.rfind(\".\", 0, max_length_seed)\n",
        "    if end_position > -1:\n",
        "        seed_text1 = seed_text1[:end_position]\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Define a class for narrative generation\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Define a class for narrative generation\n",
        "class NarrativeGenerator:\n",
        "    def __init__(self, model_name):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "    def generate_narrative(self, seed_text, max_length=1500, temperature=0.8):\n",
        "        # Tokenize the seed_text and truncate it to fit within the model's limit\n",
        "        inputs = self.tokenizer.encode(seed_text, return_tensors='pt', truncation=True)\n",
        "        outputs = self.model.generate(inputs, do_sample=True, max_length=max_length, temperature=temperature, num_return_sequences=1)\n",
        "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Instantiate the generator with the GPT-2 Medium model\n",
        "narrative_generator = NarrativeGenerator('gpt2-medium')\n",
        "\n",
        "# Generate a narrative from the seed text\n",
        "narrative = narrative_generator.generate_narrative(seed_text1, max_length=1024)\n",
        "print(narrative)\n",
        "\n"
      ],
      "metadata": {
        "id": "rLExWoK255vA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
